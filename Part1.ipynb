
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometric estimation of an IRL-based market portfolio model. Part II: QED\n",
    "\n",
    "Welcome to your final course project on Advanced Topic RL in Finance. In this project you will: \n",
    "\n",
    "- Explore and estimate an IRL-based model of market returns (the \"QED\" model) that is obtained by a generalization of   a model that you analyzed in the previous course\n",
    "- Respectively, you are expected to re-utilize parts of your previous code from the course project from Course 3: RL (but you can also start from scratch - the template provided here is nearly identical to the one offered to you in course 3)\n",
    "- Investige the role of non-linearities in price dynamics\n",
    "- Investigate the role and impact of choices of different signals on model estimation and trading strategies\n",
    " \n",
    "\n",
    "**Instructions for project structure and grading principles :**\n",
    "\n",
    "- This is a project that will be graded based on a peer-to-peer review. The project consists of four parts. The maximum score for each part is 10, so that maximum score you can give your peers (and they can give you) is 40. The parts are as follows (more detailed instructions are in specific cells below):\n",
    "\n",
    "- **Part 1**: Estimate the model using the DJI portfolio of 30 stocks, first without signals, and then using simple signals such as simple moving averages constructed below (Max 10 point).\n",
    "\n",
    "- **Part 2**: Explore the implications of calibrated model parameters for default probabilities of stocks in your portfolio. Present your conclusions and observations. (Max 10 point).\n",
    "\n",
    "- **Part 3**: Experiment with other signals and investigate the impact on model calibration obtained with alternative signals. Present your conclusions and observations. (Max 10 points).\n",
    "\n",
    "- **Part 4** : Show me something else. This part is optional. Come up with your own idea of an interesting analysis.\n",
    "For example, you can repeat your analysis for the S&P portfolio.\n",
    "Or maybe you can build a strategy using an optimal market-implied policy estimated from this model, and compare it with PCA and absorption ratio strategies that we built in Course 2. Or anything else.  (Max 10 points).\n",
    "\n",
    "**Instructions for formatting your notebook and packages use can use **\n",
    "\n",
    "- Use one or more cells of the notebook for each section of the project. Each section is marked by a header cell below. Insert your cells between them without changing the sequence. \n",
    "\n",
    "- Think of an optimal presentation of your results and conclusions. Think of how hard or easy it will be for your fellow students to follow your logic and presentation. When you are grading others, you can add or subtract point for the quality of presentation.\n",
    "\n",
    "- You will be using Python 3 in this project. Using TensorFlow is encouraged but is not strictly necessary, you can use optimization algorithms available in scipy or scikit-learn packages. If you use any non-standard packages, you should state all neccessary additional imports (or instructions how to install any additional modules you use in a top cell of your notebook. If you create a new portfolio for parts 3 and 4 in the project, make your code for creating your dataset replicable as well, so that your grader can reproduce your code locally on his/her machine.   \n",
    "\n",
    "- Try to write a clean code that can be followed by your peer reviewer. When you are the reviewer, you can add or subtract point for the quality of code. \n",
    "\n",
    "\n",
    "**After completing this project you will:**\n",
    "- Get experience with building and estimation of your second IRL based model of market dynamics.\n",
    "- Develop intuition and understanding about the role of non-linearities in dynamics model. \n",
    "- Develop intuition on whether the same model could be calibrated to both equity and credit data.\n",
    "- Be able to implement trading strategies based on this method.\n",
    "\n",
    "Let's get started!"
]
}
# ## The IRL-based model of stock returns
# 
# In Week 4 lectures of our course we found that optimal investment policy in the problem of inverse portfolio optimization is a Gaussian policy
# 
# $$ \pi_{\theta}({\bf a}_t |{\bf y}_t ) =   \mathcal{N}\left({\bf a}_t | \bf{A}_0 + \bf{A}_1 {\bf y}_t, \Sigma_p \right) $$
# 
# Here $ {\bf y}_t $ is a vector of dollar position in the portfolio, and $ \bf{A}_0 $, $ \bf{A}_1 $ and $ \Sigma_p $ are parameters defining a Gaussian policy.   
# 
# We said in the lecture that such Gaussian policy is found for both cases of a single investor and a market portfolio. We also sketched a numerical scheme that can iteratively compute coefficients $ \bf{A}_0$, $ \bf{A}_1 $ and $ \Sigma_p $ using a combination of a RL algorithm called G-learning and a trajectory optimization algorithm.
# 
# In this project, you will explore implications and estimation of this IRL-based model for the most interesting case - the market portfolio. It turns out that for this case, the model can be estimated in an easier way using a conventional Maximum Likelihood approach. To this end, we will re-formulate the model for this particular case in three easy steps.
# 
# 
# Recall that for a vector of $ N $ stocks, we introduced a size $ 2 N $-action vector 
# $ {\bf a}_t = [{\bf u}_t^{(+)}, {\bf u}_t^{(-)}] $, so that an action $ {\bf u}_t $ was defined as a difference of two non-negative numbers 
# $ {\bf u}_t = {\bf u}_t^{(+)} -  {\bf u}_t^{(-)} = [{\bf 1}, - {\bf 1}] {\bf a}_t \equiv {\bf 1}_{-1}^{T} {\bf a}_t $.
# 
# Therefore, the joint distribution of $ {\bf a}_t = [{\bf u}_t^{(+)}, {\bf u}_t^{(-)} ] $ is given by our Gaussian policy
# $  \pi_{\theta}({\bf a}_t |{\bf y}_t ) $. This means that the distribution of 
# $ {\bf u}_t = {\bf u}_t^{(+)} -  {\bf u}_t^{(-)} $ is also Gaussian. Let us write it therefore as follows:
# 
# $$
# \pi_{\theta}({\bf u}_t |{\bf y}_t ) =   \mathcal{N}\left({\bf u}_t | \bf{U}_0 + \bf{U}_1 {\bf y}_t, \Sigma_u \right) 
# $$
# 
# Here $ \bf{U}_0 = {\bf 1}_{-1}^{T}  \bf{A}_0 $ and $ \bf{U}_1 =  {\bf 1}_{-1}^{T}  \bf{A}_1 $.
# 
# This means that $ {\bf u}_t $ is a Gaussian random variable that we can write as follows:
# 
# $$
# {\bf u}_t = \bf{U}_0 + \bf{U}_1 {\bf y}_t + \varepsilon_t^{(u)}  = \bf{U}_0 + \bf{U}_1^{(x)} {\bf x}_t + \bf{U}_1^{(z)} {\bf z}_t + \varepsilon_t^{(u)} 
# $$
# 
# where $ \varepsilon_t^{(u)} \sim \mathcal{N}(0,\Sigma_u) $ is a Gaussian random noise.  
# 
# The most important feature of this expression that we need going forward is is linear dependence on the state $ {\bf x}_t $. 
# This is the only result that we will use in order to construct a simple dynamic market model resulting from our IRL model. We use a deterministic limit of this equation, where in addition we set $ \bf{U}_0 = \bf{U}_1^{(z)} = 0 $, and replace $ \bf{U}_1^{(x)} \rightarrow \phi $ to simplify the notation. We thus obtain a simple deterministic policy
# 
# $$
# \label{determ_u}
# {\bf u}_t =  \phi  {\bf x}_t 
# $$
# 
# Next, let us recall the state equation and return equation (where we reinstate a time step $ \Delta t $,
# and $ \circ $ stands for an element-wise (Hadamard) product):
# 
# $$
# X_{t+ \Delta t} = (1 + r_t \Delta t) \circ (  X_t +  u_t  \Delta t)  
# $$
# $$
# r_t   = r_f + {\bf w} {\bf z}_t -  \mu  u_t + \frac{\sigma}{ \sqrt{ \Delta t}} \varepsilon_t 
# $$
# where $ r_f $ is a risk-free rate, $ \Delta t $ is a time step, $ {\bf z}_t $ is a vector of predictors with weights $ {\bf w} $, $ \mu $ is a market impact parameter with a linear impact specification, and $ \varepsilon_t \sim \mathcal{N} (\cdot| 0, 1) $ is a white noise residual.
# 
# 
# Eliminating $ u_t $ from these expressions and simplifying, we obtain
# $$ \Delta  X_t = \mu  \phi  ( 1 + \phi \Delta t) \circ  X_t \circ \left(  \frac{r_f (1 + \phi \Delta t)  + \phi}{ \mu \phi (1+ \phi \Delta t )}  -  X_t \right) \Delta t + 
# ( 1 + \phi \Delta t) X_t  \circ \left[ {\bf w} {\bf z}_t  \Delta t +  \sigma \sqrt{ \Delta t} \varepsilon_t \right]
# $$
# Finally, assuming that $ \phi \Delta t \ll 1 $ and taking the continuous-time limit $  \Delta t \rightarrow dt $, we obtain 
# 
# $$
# d X_t = \kappa \circ X_t \circ \left( \frac{\theta}{\kappa} - X_t \right) dt +  X_t \circ \left[ {\bf w} {\bf z}_t \, dt + \sigma d W_t \right]
# $$
# where $\kappa   =   \mu  \phi $, $ \theta  =   r_f + \phi $, and $ W_t $ is a standard Brownian motion.
# 
# Please note that this equation describes dynamics with a quadratic mean reversion. It is quite different from models with linear mean reversion such as the Ornstein-Uhlenbeck (OU) process. 
# 
# Without signals $ {\bf z}_t $, this process is known in the literature as a Geometric Mean Reversion (GMR) process. It has been used (for a one-dimensional setting) by Dixit and Pyndick (" Investment Under Uncertainty", Princeton 1994), and investigated (also for 1D) by Ewald and Yang ("Geometric Mean Reversion: Formulas for the Equilibrium Density and Analytic Moment Matching", {\it University of 
# St. Andrews Economics Preprints}, 2007). We have found that such dynamics (in a multi-variate setting) can also be obtained for market caps (or equivalently for stock prices, so long as the number of shares is held fixed) using Inverse Reinforcement Learning! 
# 
# (For more details, see I. Halperin and I. Feldshteyn, "Market Self-Learning of Signals, Impact and Optimal Trading: Invisible Hand Inference with Free Energy.
# (or, How We Learned to Stop Worrying and Love Bounded Rationality)", https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=3174498) 
# 

# In[25]:


import pandas as pd
import numpy as np
import tensorflow as tf

import matplotlib.pyplot as plt
from datetime import datetime


# In[26]:


# read the data to a Dataframe
df_cap = pd.read_csv('dja_cap.csv')


# In[27]:


# add dates
dates = pd.bdate_range(start='2010-01-04', end=None, periods=df_cap.shape[0], freq='B')
df_cap['date'] = dates

df_cap.set_index('date',inplace=True)
df_cap.head()


# ## Let us build some signals 
# 
# Here we provide a "warm start" by computing two simple moving average signals that you can use as benchmark in your analysis.

# ### Generate moving averages

# In[28]:


# Calculating the short-window (10 days) simple moving average

window_1 = 10

short_rolling = df_cap.rolling(window=window_1).mean()
# short_rolling.head(20)


# In[29]:


# Calculating the long-window (30 days) simple moving average

window_2 = 30
long_rolling = df_cap.rolling(window=window_2).mean()
# long_rolling.tail()


# ### Plot three years of AAPL stock:

# In[30]:


ticker = 'AAPL'
start_date = '2015-01-01'
end_date = '2017-12-31'

fig = plt.figure(figsize=(10,6))
ax = fig.add_subplot(1,1,1)

ax.plot(df_cap.loc[start_date:end_date, :].index, df_cap.loc[start_date:end_date, 'AAPL'], label='Cap')
ax.plot(long_rolling.loc[start_date:end_date, :].index, long_rolling.loc[start_date:end_date, 'AAPL'], 
          label = '%d-days SMA' % window_2)
ax.plot(short_rolling.loc[start_date:end_date, :].index, short_rolling.loc[start_date:end_date, 'AAPL'], 
         label = '%d-days SMA' % window_1)

ax.legend(loc='best')
ax.set_ylabel('Cap in $')

plt.show()


# ## Part 1: Model calibration with moving average signals (Max 10 points)

# Recall the equation for the dynamics of market portfolio: 
# 
# $$ \Delta {\bf x}_t = \kappa_x \circ  {\bf x}_t \circ 
# \left( {\bf W}{\bf z}_t'  - {\bf x}_t \right)  +  {\bf x}_t  \circ \varepsilon_t^{(x)} $$
# 
# Here we change the notation a bit. Now $ {\bf z}_t' $ is an extended vector of predictors that includes a constant unit predictor $  {\bf z}_t' = [1, {\bf z}_t ]^T $. Therefore, for each name, if you have $ K = 2 $ signals, an extended vector of signals $ {\bf z}_t' $ is of length $ K + 1 $, and the  $ W $ stands for a factor loading matrix.
# The negative log-likelihood function for observable data with this model is therefore
# 
# $$  LL_M (\Theta) = - \log \prod_{t=0}^{T-1} 
# \frac{1}{ \sqrt{ (2 \pi)^{N}  \left| \Sigma_x \right| }} 
# e^{ - \frac{1}{2} \left(   {\bf v}_t
#  \right)^{T} 
# \Sigma_x^{-1}  
# \left(  {\bf v}_t \right)} $$
# 
# where
# 
# $$  {\bf v}_t \equiv \frac{{\bf x}_{t+1} -  {\bf x}_{t}}{{\bf x}_{t}}  
# -  \kappa_x \circ \left({\bf W} {\bf z}_t'   - {\bf x}_t \right)  $$
# 
# and $ \Sigma_x $ is the covariance matrix that was specified above in terms of other parameters. Here we directly infer the value of $ \Sigma_x $, along with other parameters, from data, so we will not use these previous expressions. 
# 
# Parameters that you have to estimate from data are therefore the vector of mean reversion speed 
# parameters $ \kappa_x $, factor loading matrix $ {\bf W} \equiv {\bf w}_z' $, and covariance matrix $ \Sigma_x $. 
# 
# Now, you are free to impose some structure on this parameters. Here are some choice, in the order of increasing complexity:
# 
# - assume that all values in vector-valued and matrix-valued parameters are the same, so that they can parametrized by scalars, e.g. $ \kappa_x = \kappa {\bf 1}_N $ where $ \kappa $ is a scalar value, and $ {\bf 1}_N $ is a vector of ones of length $ N $ where $ N $ is the number of stocks in the market portfolio. You can proceed similarly with specification of factor loading matrix $ W' $. Assume that all values in (diagonal!) factor loading matrices are the same for all names, and assume that all correlations and variances in the covariance matrix $ \Sigma_x $ are the same for all names.   
# 
# - Assume that all values are the same only within a given industrial sector.
# 
# 
# - You can also change the units. For example, you can consider logs of market caps instead of market caps themselves, ie. change the variable from $ {\bf x}_t  $ to $ {\bf q}_t = \log {\bf x}_t $
# 

# In[31]:


# Put the rest of you code and analysis for Part I here 

# Number of stocks in the market portfolio
T = df_cap.shape[0]
N = df_cap.shape[1]

# Select the available (not NaN) data from 'short_rolling' and 'long_rolling'
t0_short = int(np.where(short_rolling.index == short_rolling.first_valid_index())[0])
t0_long = int(np.where(long_rolling.index == long_rolling.first_valid_index())[0])
short_rolling_nna = short_rolling[t0_short:(T - 1)]
long_rolling_nna = long_rolling[t0_long:(T - 1)]

# Construct the time series for the market cap
mkt_cap = df_cap.sum(axis=1)
avg_mkt_cap = mkt_cap.mean()

# Scale the data
# Determine the long and short average rolling values and demean
short_rolling_avg_nna = short_rolling_nna / avg_mkt_cap
long_rolling_avg_nna = long_rolling_nna / avg_mkt_cap

# The data
signal_1 = short_rolling_avg_nna
signal_2 = long_rolling_avg_nna


# In[32]:


# Plot the index and rolling averages
fig=plt.figure(figsize=(14, N))
plt.suptitle('Market cap vs fitted mean reversion level (returns in Billion USD)',size=20)
plt.subplots_adjust(top=.95)

stocks = df_cap.columns[:N]
for index, stock in enumerate(stocks,1):
    plt.subplot(np.ceil(N/3),3,index)
    plt.plot(df_cap.index, df_cap[[stock]].values*1e-9, label='Market Index')
    plt.plot(short_rolling_nna.index, short_rolling_nna[[stock]].values*1e-9, label='10 days rolling')
    plt.plot(long_rolling_nna.index, long_rolling_nna[[stock]].values*1e-9, label='30 days rolling')
    plt.title(stock,size=12)
    plt.xticks([])             


# In[33]:


plt.show()


# In[34]:


from sklearn.preprocessing import StandardScaler
# Consider log returns instead. Demean and scale to unit variance

log_df_cap_mat_std = StandardScaler().fit_transform(df_cap.values)
log_df_cap_std = pd.DataFrame(data = log_df_cap_mat_std, 
                              index = df_cap.index,
                              columns = df_cap.columns.values)
log_short_rolling = log_df_cap_std.rolling(window=window_1).mean()
log_long_rolling = log_df_cap_std.rolling(window=window_2).mean()

fig = plt.figure(figsize=(10,6))
ax = fig.add_subplot(1,1,1)
plt.suptitle('Market cap demeaned and stanadrdized for AAPL',size=20)

ax.plot(log_df_cap_std.index, log_df_cap_std.loc[:, 'AAPL'], label='Log-Returns std')
ax.plot(log_long_rolling.index, log_long_rolling.loc[:, 'AAPL'], 
          label = '%d-days SMA' % window_2)
ax.plot(log_short_rolling.index, log_short_rolling.loc[:, 'AAPL'], 
         label = '%d-days SMA' % window_1)

ax.legend(loc='best')
ax.set_ylabel('log-ret')

plt.show()

# From the graph we can see that there is a clear upward trend

